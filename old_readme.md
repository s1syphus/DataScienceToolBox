# DataScienceToolBox

---
## Purpose Paragraph Put something here, probably change the name Kaggle, learning,.. etc.

This document might be too large, possibly break down into several different documents
by topic. Links should solve any issues navigating

https://en.wikipedia.org/wiki/List_of_machine_learning_concepts

---

## Table of Contents

1. [Data Techniques](#data-techniques)
2. [Machine Learning Techniques](#machine-learning-techniques)
	1. [Supervised Learning]
		* [Artificial Neural Network (ANN)]
		* [Averaged One-Dependence Estimators (AODE)]
		* [Bayesian Statistics]
		* [Case-Based Reasoning]
		* [Gaussian Process Regression]
		* [Gene Expression Programming]
		* [Group Method of Data Handling (GMDH)]
		* [Inductive Logic Programming]
		* [Instance-Based Learning]
		* [Lazy Learning]
		* [Learning Vector Quantization]
		* [Logistic Model Tree]
		* [Minimum Message Length]
		* [Probably Approximately Correct Learning (PAC)]
		* [Ripple Down Rules]
		* [Support Vector Machines (SVM)]
		* [Random Forests]
		* [Ensemble Learning]
		* [Ordinal Classification]
		* [Information Fuzzy Networks (IFN)]
		* [Conditional Random Field]
		* [ANOVA]
		* [Linear Classifiers]
		* [Quadratic Classifiers]
		* [Nearest Neighbor]
		* [Boosting]
		* [Decision Trees]
		* [Bayesian Networks]
		* [Hidden Markov Models]
	2. [Unsupervised Learning]
		* [Expectation-Maximization Algorithm]
		* [Vector Quantization]
		* [Generative Topographic Map]
		* [Information Bottleneck Method]
		* [Association Rule Learning]
		* [Hierarchical Clustering]
		* [Cluster Analysis]
		* [Outlier Detection]
	3. [Deep Learning]
		* [Deep Belief Networks]
		* [Deep Boltzman Machines]
		* [Deep Convolutional Neural Networks (CNN)]
		* [Deep Recurrent Neural Networks (RNN)]
		* [Hierarchical Temporal Memory]
	4. [Semi-Supervised Learning]
		* [Generative Models]
		* [Low-Density Separation]
		* [Graph-Based Methods]
		* [Co-Training]
	5. [Reinforcement Learning]
		* [Temporal Difference Learning]
		* [Q-Learning]
		* [Learning Automata]
		* [State-Action-Reward-State-Action (SARSA)]
3. [Choosing the Right Algorithm]
4. [Conclusion]


---

## Data Techniques ##
Talk about data, structure, cleanup, sources, etc

k-folds other stuff

---

## Machine Learning Techniques ##
Overview paragraph

---

## Supervised Learning ##
Supervised learning stuff


## Artificial Neural Network (ANN) ##
See [Deep Learning]

## Averaged One-Dependence Estimators (AODE) ##
Averaged One-Dependence Estimators is a probabilistic classification technique. It is 
an improvement on the [Naive Bayes Estimator](#bayesian-statistics). This technique produces
class probabilities rather than single classes which allows more flexibility by having the
end-user set the threshold for selection. The computational complexity for training is 
O(ln^2) and O(kn^2) for classificiation where n is the number of features, l is the number of . This means 


## Bayesian Statistics ##

## Case-Based Reasoning ##

## Gaussian Process Regression ##

## Gene Expression Programming ##

## Group Method of Data Handling (GMDH) ##

## Inductive Logic Programming ##

## Instance-Based Learning ##

## Lazy Learning ##

## Learning Automata ##

## Learning Vector Quantization ##

## Logistic Model Tree ##

## Minimum Message Length ##

## Probably Approximately Correct Learning (PAC) ##

## Ripple Down Rules ##
A knowledge acquisition methodology

## Support Vector Machines (SVM) ##
This should be a fairly large entry - Important

## Random Forests ##

## Ensemble Learning ##

## Ordinal Classification ##

## Information Fuzzy Networks (IFN) ##

## Conditional Random Field ##

## ANOVA ##

## Linear Classifiers ##
Lots of stuff here, more of a group
need to rearrange this stuff by heirarchy

## Quadratic Classifiers ##

## Nearest Neighbor ##

## Boosting ##

## Decision Trees ##
Add all the different algorithms (or at least some)

## Bayesian Networks

## Hidden Markov Models

---

## Unsupervised Learning
Paragraph about unsupervised learning

## Expectation-Maximization Algorithm

## Vector Quantization ##

## Generative Topographic Map ##

## Information Bottleneck Method ##


## Association Rule Learning
* Apriori algorithm
* Eclat algorithm
* FP-growth algorithm

## Hierarchical Clustering
* Single-linkage clustering
* Conceptual clustering

## Cluster Analysis
* K-means algorithm
* Fuzzy clustering
* DBSCAN
* OPTICS algorithm

## Outlier Detection

---

## Deep Learning ##
Explain neural networks/deep learning stuff here

## Deep Belief Networks

## Deep Boltzman Machines

## Deep Convolutional Neural Networks (CNN)

## Deep Recurrent Neural Networks (RNN)

## Hierarchical Temporal Memory

---

## Semi-Supervised Learning
Paragraph about semi-supervised learning

## Generative Models

## Low-Density Separation

## Graph-Based Methods

## Co-Training

---

## Reinforcement Learning
Paragraph about semi-supervised learning

## Temporal Difference Learning

## Q-Learning

## Learning Automata

## State-Action-Reward-State-Action (SARSA)


## Choosing the Right Algorithm
This is where the flow chart is going to go

## Conclusion


---

##TODO

* Write descriptions of main ideas/purposes of general classes of machine learning algorithms
* add more details/break down the classes into subclasses
* add in optimizations of the major algorithms (not a priority)
* Write purpose paragraph, ie why I am making this
* Add in python/pseudocode example of algorithms
* make a flow-chart or something that helps decide the best algorithm for a given task
* add benchmarks - AWS EC2? That would keep it consistent
* talk about scalability/gpu speedup
* add references
* write working example code (probably for the benchmarks) - make it easily deployable to vagrant and/or EC2
* Make abbrievated/priority version - not sure if this should be seperate or just
change the ordering


